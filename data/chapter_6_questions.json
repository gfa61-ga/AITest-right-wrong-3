[
  {
    "question": "Ένα τεχνητό νευρωνικό δίκτυο αποτελείται από τεχνητούς νευρώνες, βάρη σύνδεσης και συναρτήσεις ενεργοποίησης, που συνεργάζονται για να μάθουν από παραδείγματα εισόδου–εξόδου.",
    "answer": true,
    "chapter_number": 6
  },
  {
    "question": "Τα νευρωνικά δίκτυα απαιτούν πλήρως χειροκίνητους κανόνες από ειδικούς και δεν μπορούν να προσαρμόσουν τα βάρη τους αυτόματα με βάση δεδομένα εκπαίδευσης.",
    "answer": false,
    "chapter_number": 6,
    "right_answer": "Βασικό πλεονέκτημα των νευρωνικών δικτύων είναι ότι μαθαίνουν αυτόματα από δεδομένα, προσαρμόζοντας τα βάρη τους μέσω διαδικασιών εκπαίδευσης όπως η οπισθοδιάδοση."
  },
  {
    "question": "Τα συνελικτικά νευρωνικά δίκτυα (CNN) αξιοποιούν φίλτρα που «σκανάρουν» την εικόνα για να εντοπίζουν τοπικά πρότυπα, όπως ακμές και σχήματα, τα οποία σταδιακά συνθέτουν πιο σύνθετα χαρακτηριστικά.",
    "answer": true,
    "chapter_number": 6
  },
  {
    "question": "Τα CNN είναι κατάλληλα κυρίως για πίνακες αριθμών χωρίς χωρική δομή, ενώ σε δεδομένα εικόνας συνήθως αποδίδουν χειρότερα από απλά πλήρως συνδεδεμένα δίκτυα.",
    "answer": false,
    "chapter_number": 6,
    "right_answer": "Τα CNN έχουν σχεδιαστεί ειδικά για δεδομένα με χωρική δομή, όπως εικόνες και βίντεο, και συνήθως υπερέχουν σε τέτοια προβλήματα σε σχέση με απλά πλήρως συνδεδεμένα δίκτυα."
  },
  {
    "question": "Τα αναδρομικά νευρωνικά δίκτυα (RNN) εισάγουν έννοια «μνήμης», επιτρέποντας τη μοντελοποίηση ακολουθιών και χρονικών εξαρτήσεων σε δεδομένα όπως κείμενο ή χρονοσειρές.",
    "answer": true,
    "chapter_number": 6
  },
  {
    "question": "Επειδή τα κλασικά πολυεπίπεδα perceptrons (MLP) αρκούν για κάθε τύπο προβλήματος, τα RNN δεν προσφέρουν ιδιαίτερο πλεονέκτημα σε δεδομένα με χρονικές εξαρτήσεις.",
    "answer": false,
    "chapter_number": 6,
    "right_answer": "Τα RNN, καθώς και οι παραλλαγές τους (LSTM, GRU), έχουν σχεδιαστεί ειδικά για ακολουθιακά δεδομένα και συχνά αποδίδουν καλύτερα από απλά MLP σε προβλήματα με ισχυρή χρονική δομή."
  },
  {
    "question": "Οι μετασχηματιστές (Transformers) βασίζονται σε μηχανισμούς αυτοπροσοχής (self-attention) και μπορούν να επεξεργάζονται ταυτόχρονα μεγάλες ακολουθίες, κάτι που τους έκανε κυρίαρχους σε εφαρμογές φυσικής γλώσσας.",
    "answer": true,
    "chapter_number": 6
  },
  {
    "question": "Τα μοντέλα Transformers έχουν πλέον εγκαταλειφθεί σε προβλήματα γλώσσας, καθώς τα κλασικά συμβολικά συστήματα κανόνων αποδεικνύονται σταθερά ανώτερα σε όλες τις μετρικές.",
    "answer": false,
    "chapter_number": 6,
    "right_answer": "Τα μοντέλα Transformers αποτελούν σύγχρονο πρότυπο στην επεξεργασία φυσικής γλώσσας και άλλων πεδίων, ενώ τα συμβολικά συστήματα χρησιμοποιούνται συμπληρωματικά σε ορισμένα σενάρια."
  },
  {
    "question": "Τα αυτόματα κωδικοποιητικά δίκτυα (Autoencoders) μπορούν να χρησιμοποιηθούν για μείωση διαστατικότητας, μάθηση συμπιεσμένων αναπαραστάσεων και ανίχνευση ανωμαλιών.",
    "answer": true,
    "chapter_number": 6
  },
  {
    "question": "Σε ένα τυπικό autoencoder, ο κωδικοποιητής εκπαιδεύεται να προσθέτει όσο το δυνατόν περισσότερο θόρυβο στην είσοδο, ώστε το δίκτυο να παράγει εντελώς διαφορετική έξοδο από το αρχικό σήμα.",
    "answer": false,
    "chapter_number": 6,
    "right_answer": "Ο στόχος ενός autoencoder είναι να συμπιέσει και να ανακατασκευάσει την είσοδο όσο γίνεται καλύτερα· σε παραλλαγές όπως τα denoising autoencoders, το δίκτυο μαθαίνει να αφαιρεί θόρυβο, όχι να τον μεγιστοποιεί."
  },
  {
    "question": "Η διαδικασία εκπαίδευσης νευρωνικού δικτύου περιλαμβάνει διάδοση προς τα εμπρός (forward pass), υπολογισμό σφάλματος και οπισθοδιάδοση (backpropagation) για την ενημέρωση των βαρών.",
    "answer": true,
    "chapter_number": 6
  },
  {
    "question": "Κατά την οπισθοδιάδοση, ενημερώνονται μόνο τα βάρη του επιπέδου εξόδου, ενώ τα κρυφά επίπεδα παραμένουν σταθερά για να διατηρείται η αρχική δομή του δικτύου.",
    "answer": false,
    "chapter_number": 6,
    "right_answer": "Η οπισθοδιάδοση διαδίδει τις παραγώγους του σφάλματος προς τα πίσω, ενημερώνοντας τόσο τα βάρη εξόδου όσο και των κρυφών επιπέδων ώστε να βελτιωθεί η συνολική απόδοση."
  },
  {
    "question": "Ο ρυθμός μάθησης (learning rate) επηρεάζει το μέγεθος των βημάτων ενημέρωσης των βαρών· αν είναι πολύ μεγάλος, η εκπαίδευση μπορεί να γίνει ασταθής, ενώ αν είναι πολύ μικρός, η σύγκλιση μπορεί να είναι αργή.",
    "answer": true,
    "chapter_number": 6
  },
  {
    "question": "Η προσθήκη συνεχώς περισσότερων επιπέδων και νευρώνων σε ένα δίκτυο εξασφαλίζει αυτόματα μικρότερο κίνδυνο υπερπροσαρμογής (overfitting) και καλύτερη γενίκευση.",
    "answer": false,
    "chapter_number": 6,
    "right_answer": "Μεγαλύτερα δίκτυα έχουν μεγαλύτερη ικανότητα έκφρασης αλλά και αυξημένο κίνδυνο υπερπροσαρμογής· απαιτούνται τεχνικές όπως regularization, dropout και early stopping για καλή γενίκευση."
  },
  {
    "question": "Η εκπαίδευση βαθιών νευρωνικών δικτύων συχνά απαιτεί μεγάλο όγκο δεδομένων, ισχυρούς υπολογιστικούς πόρους (π.χ. GPU) και μπορεί να είναι χρονοβόρα διαδικασία.",
    "answer": true,
    "chapter_number": 6
  },
  {
    "question": "Σύμφωνα με το κεφάλαιο, τα νευρωνικά δίκτυα θεωρούνται εγγενώς ακατάλληλα για επεξεργασία Big Data, επειδή δεν μπορούν να κλιμακωθούν σε μεγάλα σύνολα δεδομένων.",
    "answer": false,
    "chapter_number": 6,
    "right_answer": "Το υλικό αναφέρει ότι τα νευρωνικά δίκτυα είναι ιδιαίτερα ισχυρά σε περιβάλλοντα Big Data, παρότι υπάρχουν προκλήσεις σε υπολογιστικούς πόρους, χρόνο εκπαίδευσης και διαχείριση μεγάλων συνόλων δεδομένων."
  },
  {
    "question": "Βιβλιοθήκες και πλατφόρμες όπως η Python με scikit-learn, καθώς και τα TensorFlow και Keras, διευκολύνουν σημαντικά την ανάπτυξη και εκπαίδευση μοντέλων δένδρων αποφάσεων και νευρωνικών δικτύων.",
    "answer": true,
    "chapter_number": 6
  },
  {
    "question": "Επειδή τα σύγχρονα εργαλεία βαθιάς μάθησης αυτοματοποιούν πολλές διαδικασίες, η κατανόηση της θεωρίας πίσω από τα νευρωνικά δίκτυα δεν θεωρείται πλέον απαραίτητη για υπεύθυνες εφαρμογές.",
    "answer": false,
    "chapter_number": 6,
    "right_answer": "Η καλή κατανόηση των θεωρητικών αρχών (αρχιτεκτονικές, βελτιστοποίηση, υπερπροσαρμογή, περιορισμοί) παραμένει κρίσιμη για τον σωστό και υπεύθυνο σχεδιασμό λύσεων ΤΝ."
  },
  {
    "question": "Για την αξιόπιστη αξιολόγηση νευρωνικού δικτύου, χρησιμοποιούνται συνήθως ξεχωριστά σύνολα εκπαίδευσης, επικύρωσης και ελέγχου, καθώς και μετρικές όπως η απώλεια (loss) και η ακρίβεια (accuracy) ανά εποχή.",
    "answer": true,
    "chapter_number": 6
  },
  {
    "question": "Αφού εκπαιδευτεί ένα νευρωνικό δίκτυο με ικανοποιητικά αποτελέσματα, δεν είναι απαραίτητο να παρακολουθείται ή να επανεκπαιδεύεται, ακόμη κι αν αλλάξουν οι συνθήκες ή τα δεδομένα εισόδου.",
    "answer": false,
    "chapter_number": 6,
    "right_answer": "Η απόδοση ενός δικτύου μπορεί να υποβαθμιστεί όταν αλλάξουν τα δεδομένα ή το περιβάλλον (data drift), οπότε χρειάζεται παρακολούθηση, επανεκπαίδευση και πιθανή αναπροσαρμογή του μοντέλου."
  }
]
